# Deployment Guide - Bibidi Backend

Complete guide for deploying the Bibidi Backend to AWS EC2 using CloudFormation and GitHub Actions.

## Table of Contents

- [AWS EC2 Deployment (Production)](#aws-ec2-deployment-production)
- [Environment Variables Reference](#environment-variables-reference)
- [Alternative Platforms](#alternative-platforms)

---

## AWS EC2 Deployment (Production)

### Overview

This deployment uses:
- **AWS CloudFormation** - Infrastructure as Code
- **GitHub Actions** - CI/CD pipeline
- **AWS CodeDeploy** - Automated deployment to EC2
- **OIDC Authentication** - Secure, keyless authentication
- **Auto Scaling Group** - High availability (2-4 instances)
- **Application Load Balancer** - Traffic distribution
- **PM2** - Node.js process management

### Prerequisites

1. **AWS Account** with administrative access
2. **AWS CLI** installed and configured
   ```bash
   # Install AWS CLI (macOS)
   brew install awscli
   
   # Configure credentials
   aws configure
   ```

3. **Verify AWS CLI access**
   ```bash
   aws sts get-caller-identity
   ```

#### Required IAM permissions

Make sure the IAM identity (or CloudFormation execution role) that runs the commands below can create every resource in `cloudformation/backend-stack.yaml`. In addition to standard CloudFormation actions, grant the ability to manage VPC/EC2 networking, Auto Scaling, Elastic Load Balancing, S3 buckets, RDS instances, and IAM roles. Scope `iam:PassRole` to the stack-created roles such as `*-BibidiBackend-EC2Role`, `*-CodeDeployServiceRole-BibidiBackend`, `*-GitHubActionsRole-BibidiBackend`, and `*-RDSMonitoringRole`. If you rely on `PowerUserAccess`, layer these explicit permissions on top or use a dedicated CloudFormation execution role.

### Step 1: Deploy CloudFormation Stack

```bash
cd bibidi_backend

aws cloudformation create-stack \
  --stack-name BibidiBackendStack \
  --template-body file://cloudformation/backend-stack.yaml \
  --parameters \
    ParameterKey=GitHubOrg,ParameterValue=Frame-and-Furnish \
    ParameterKey=GitHubRepo,ParameterValue=bibidi_backend \
    ParameterKey=EnvironmentName,ParameterValue=production \
    ParameterKey=InstanceType,ParameterValue=t3.small \
  --capabilities CAPABILITY_NAMED_IAM \
  --region ca-central-1
```

Wait 10-15 minutes for completion:
```bash
aws cloudformation wait stack-create-complete \
  --stack-name BibidiBackendStack \
  --region ca-central-1
```

> **Tip:** Override capacity and instance sizing by supplying additional `ParameterKey=...` pairs (for example `MinSize`, `MaxSize`, or `DesiredCapacity`). For template updates, prefer `aws cloudformation deploy --capabilities CAPABILITY_NAMED_IAM --template-file cloudformation/backend-stack.yaml` so resources are modified in place rather than recreated.

### Step 2: Get Stack Outputs

```bash
aws cloudformation describe-stacks \
  --stack-name BibidiBackendStack \
  --query 'Stacks[0].Outputs' \
  --output table
```

Save these values—you'll need the first five for GitHub Secrets and the remainder for database configuration in the next step:
- `GitHubActionsRoleArn` → `AWS_ROLE_ARN`
- `S3BucketName` → `S3_BUCKET`
- `CodeDeployApplication` → `CODEDEPLOY_APP`
- `DeploymentGroup` → `CODEDEPLOY_GROUP`
- `LoadBalancerURL` → Your application URL
- `DatabaseEndpoint` → RDS hostname
- `DatabasePort` → RDS port (usually `5432`)
- `DatabaseSecretArn` → ARN for the generated master credentials
- `DatabaseName` → Default database name (`postgres`)

### Step 3: Create Secrets in AWS Secrets Manager

Use the outputs captured above to assemble your production environment variables and reuse the RDS master credentials that AWS generated for you:

1. Retrieve the autogenerated database username and password:
   ```bash
   DB_SECRET_ARN=$(aws cloudformation describe-stacks \
     --stack-name BibidiBackendStack \
     --query "Stacks[0].Outputs[?OutputKey=='DatabaseSecretArn'].OutputValue" \
     --output text)

   aws secretsmanager get-secret-value \
     --secret-id "$DB_SECRET_ARN" \
     --query 'SecretString' \
     --output text
   ```
   The response is JSON (for example `{ "username": "bibidi_admin", "password": "<generated-password>" }`).

2. Combine those credentials with `DatabaseEndpoint`, `DatabasePort`, and `DatabaseName` to build `DATABASE_URL`, e.g.:
   ```
   postgresql://bibidi_admin:<generated-password>@<database-endpoint>:<database-port>/<database-name>
   ```

3. Create (or update) the application secret with your real values:
   ```bash
   aws secretsmanager create-secret \
     --name bibidi/backend/production \
     --description "Production environment variables for Bibidi Backend" \
     --secret-string '{
       "NODE_ENV": "production",
       "PORT": "3000",
       "DATABASE_URL": "postgresql://bibidi_admin:REPLACE_WITH_DB_PASSWORD@REPLACE_WITH_DB_HOST:REPLACE_WITH_DB_PORT/postgres",
       "JWT_SECRET": "REPLACE_WITH_STRONG_RANDOM_VALUE",
       "JWT_EXPIRES_IN": "7d",
       "FRONTEND_URL": "https://yourdomain.com",
       "STORAGE_DRIVER": "local",
       "UPLOAD_MAX_FILE_MB": "15"
     }' \
     --region ca-central-1
   ```
   If the secret already exists, swap `create-secret` for `put-secret-value` to add a new version. Update this secret whenever the RDS password rotates so the application keeps working.

### Step 4: Configure GitHub Secrets

1. Go to https://github.com/Frame-and-Furnish/bibidi_backend/settings/secrets/actions
2. Add these secrets (values from Step 2):

| Secret Name | Value |
|-------------|-------|
| `AWS_ROLE_ARN` | IAM Role ARN from CloudFormation |
| `S3_BUCKET` | S3 Bucket name from CloudFormation |
| `CODEDEPLOY_APP` | CodeDeploy application name |
| `CODEDEPLOY_GROUP` | Deployment group name |

### Step 5: Deploy

Push to main branch or manually trigger the workflow:

```bash
git push origin main
```

Or go to: https://github.com/Frame-and-Furnish/bibidi_backend/actions

### Step 6: Verify Deployment

```bash
# Test health endpoint (replace with your ALB URL)
curl http://your-alb-url.ca-central-1.elb.amazonaws.com/health
```

### Monitoring

**View Logs via SSM:**
1. AWS Console → Systems Manager → Session Manager
2. Connect to EC2 instance
```bash
pm2 logs bibidi-backend
```

**View Deployments:**
- AWS Console → CodeDeploy → Applications

### Troubleshooting

**Deployment fails:**
```bash
# Check CodeDeploy logs on EC2
sudo tail -f /var/log/aws/codedeploy-agent/codedeploy-agent.log
```

**Application not starting:**
```bash
# SSH to instance via SSM
pm2 status
pm2 logs bibidi-backend --lines 50
```

### Cost Estimation

| Service | Cost (Monthly) |
|---------|----------------|
| 2x t3.small EC2 | ~$30 |
| Application Load Balancer | ~$20 |
| EBS Storage | ~$4 |
| Data Transfer | ~$9 |
| S3 + Secrets Manager | ~$2 |
| **Total** | **~$65** |

### Rollback

CodeDeploy automatically rolls back on failure. Manual rollback:

```bash
aws deploy stop-deployment \
  --deployment-id d-XXXXXXXXX \
  --auto-rollback-enabled
```

### Cleanup

**⚠️ Deletes everything!**

```bash
# Empty S3 bucket first
aws s3 rm s3://your-bucket-name --recursive

# Delete stack
aws cloudformation delete-stack --stack-name BibidiBackendStack

# Delete secrets
aws secretsmanager delete-secret \
  --secret-id bibidi/backend/production \
  --force-delete-without-recovery
```

---

## Environment Variables Reference


**Development:**
- Uses `.env` file with `dotenv.config()`
- Local database connections
- Development secrets

**Production (AWS):**
- Environment variables from AWS Secrets Manager
- Fetched automatically during deployment
- Stored securely in `/var/www/bibidi-backend/.env` on EC2

**Required Variables:**
- `NODE_ENV=production`
- `DATABASE_URL` (production database connection string)
- `JWT_SECRET` (strong, unique secret key - use a password generator)
- `PORT` (usually set automatically by hosting platform)

**Optional:**
- `FRONTEND_URL` (production frontend URL for CORS)
- `BCRYPT_ROUNDS=12` (password hashing rounds)
- `STORAGE_DRIVER` (`local` or `s3`; defaults to `local`)
- `LOCAL_UPLOADS_DIR` (absolute path for local uploads when using `local` driver)
- `STORAGE_PUBLIC_URL` (public base URL to serve uploaded files)
- `UPLOAD_MAX_FILE_MB` (maximum upload size in megabytes; defaults to `15`)
- `S3_REGION`, `S3_BUCKET`, `S3_ACCESS_KEY_ID`, `S3_SECRET_ACCESS_KEY`, `S3_ENDPOINT` (required when using the `s3` driver)

---

## Alternative Platforms

### Heroku
```bash
# Set environment variables
heroku config:set NODE_ENV=production
heroku config:set JWT_SECRET="your-production-secret"
heroku config:set DATABASE_URL="postgresql://..."

# Deploy
git push heroku main
```

### Railway
```bash
# Environment variables set in Railway dashboard
# Automatic deployments from GitHub
```

### Docker Production
```yaml
# docker-compose.prod.yml
version: '3.8'
services:
  app:
    build: .
    environment:
      - NODE_ENV=production
      - DATABASE_URL=${DATABASE_URL}
      - JWT_SECRET=${JWT_SECRET}
    ports:
      - "3000:3000"
```

### VPS/Traditional Server
```bash
# Set environment variables in systemd service or .bashrc
export NODE_ENV=production
export DATABASE_URL="postgresql://..."
export JWT_SECRET="..."

# Build and start
npm run build
npm start
```

## Database Migrations in Production

**Important:** Run migrations before starting the application:

```bash
# Production migration workflow
npm run db:generate  # Generate migration files (if schema changed)
npm run db:migrate   # Apply migrations to production database
npm start           # Start the application
```

## Build and Deploy

```bash
# Build the application
npm run build

# Start production server
npm start
```

## Security Checklist

- [ ] Strong `JWT_SECRET` (use password generator)
- [ ] `NODE_ENV=production`
- [ ] No `.env` file in production
- [ ] HTTPS enabled
- [ ] Database connection over SSL
- [ ] Environment variables set via platform (not hardcoded)
- [ ] Error messages don't leak sensitive information